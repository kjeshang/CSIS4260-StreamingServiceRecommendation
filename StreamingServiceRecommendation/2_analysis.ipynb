{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import re\n",
    "# pip install nltk\n",
    "# import nltk\n",
    "# nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from string import punctuation\n",
    "punctuation = list(punctuation)\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_excel(\"streaming_service_titles.xlsx\", index_col=False);\n",
    "df_prep = df_combined.copy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>description</th>\n",
       "      <th>Streaming Service</th>\n",
       "      <th>Textual Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TV Show</td>\n",
       "      <td>\"The Paramedic Angel\"</td>\n",
       "      <td>2021</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Drama</td>\n",
       "      <td>The tragedy of a loving family man and paramed...</td>\n",
       "      <td>Amazon Prime</td>\n",
       "      <td>drama tragedy loving family man paramedic hero...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                  title  release_year rating genres  \\\n",
       "1  TV Show  \"The Paramedic Angel\"          2021    ALL  Drama   \n",
       "\n",
       "                                         description Streaming Service  \\\n",
       "1  The tragedy of a loving family man and paramed...      Amazon Prime   \n",
       "\n",
       "                                        Textual Info  \n",
       "1  drama tragedy loving family man paramedic hero...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(df_prep.index, index=df_prep[\"title\"]).drop_duplicates();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer(strip_accents=\"ascii\", stop_words=\"english\", min_df=0.0005, sublinear_tf=True);\n",
    "# tfidf = TfidfVectorizer(max_df=.65, min_df=1, stop_words=\"english\", use_idf=True, norm=None);\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", min_df=0.005, sublinear_tf=True);\n",
    "tfidf_matrix = tfidf.fit_transform(df_prep[\"Textual Info\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_simTFIDF = linear_kernel(tfidf_matrix, tfidf_matrix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim):\n",
    "    idx = indices[title];\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]));\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True);\n",
    "    sim_scores = sim_scores[1:11];\n",
    "    movie_indices = [i[0] for i in sim_scores];\n",
    "    dataframe1 = df_prep[[\"title\",\"description\",\"Streaming Service\"]].iloc[movie_indices];\n",
    "    # dataframe1[\"Similarity Score\"] =  sim_scores;\n",
    "    # print(type(sim_scores[3][1]))\n",
    "    # print(sim_scores[3][1])\n",
    "    similarityScores = [];\n",
    "    for i in range(len(sim_scores)):\n",
    "        similarityScores.append(sim_scores[i][1]);\n",
    "    dataframe1[\"Similarity Score\"] =  similarityScores;\n",
    "    dataframe1 = dataframe1.reset_index().rename(columns={\"index\":\"id\"});\n",
    "    return dataframe1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>Streaming Service</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12733</td>\n",
       "      <td>Narcos</td>\n",
       "      <td>The true story of Colombia's infamously violen...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.635364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3542</td>\n",
       "      <td>Cannabis</td>\n",
       "      <td>When a huge marijuana shipment falls prey to t...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.563305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2501</td>\n",
       "      <td>Better Than Us</td>\n",
       "      <td>A family on the brink of splitting up become t...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.555709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4207</td>\n",
       "      <td>Cocaine</td>\n",
       "      <td>Three films chronicle the cocaine trade's swee...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.554274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16017</td>\n",
       "      <td>She</td>\n",
       "      <td>An undercover assignment to expose a drug ring...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12734</td>\n",
       "      <td>Narcos: Mexico</td>\n",
       "      <td>Witness the birth of the Mexican drug war in t...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.541296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9936</td>\n",
       "      <td>Killer Ratings</td>\n",
       "      <td>Brazilian TV personality and politician Wallac...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.540868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12033</td>\n",
       "      <td>Mob Psycho 100</td>\n",
       "      <td>There's an organization gathering espers for a...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.531299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14657</td>\n",
       "      <td>Rake</td>\n",
       "      <td>While Cleaver Greene is a brilliant and driven...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.526270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5920</td>\n",
       "      <td>El final del paraíso</td>\n",
       "      <td>In Colombia, the DEA's new director targets a ...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.523722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                 title  \\\n",
       "0  12733                Narcos   \n",
       "1   3542              Cannabis   \n",
       "2   2501        Better Than Us   \n",
       "3   4207               Cocaine   \n",
       "4  16017                   She   \n",
       "5  12734        Narcos: Mexico   \n",
       "6   9936        Killer Ratings   \n",
       "7  12033        Mob Psycho 100   \n",
       "8  14657                  Rake   \n",
       "9   5920  El final del paraíso   \n",
       "\n",
       "                                         description Streaming Service  \\\n",
       "0  The true story of Colombia's infamously violen...           Netflix   \n",
       "1  When a huge marijuana shipment falls prey to t...           Netflix   \n",
       "2  A family on the brink of splitting up become t...           Netflix   \n",
       "3  Three films chronicle the cocaine trade's swee...           Netflix   \n",
       "4  An undercover assignment to expose a drug ring...           Netflix   \n",
       "5  Witness the birth of the Mexican drug war in t...           Netflix   \n",
       "6  Brazilian TV personality and politician Wallac...           Netflix   \n",
       "7  There's an organization gathering espers for a...           Netflix   \n",
       "8  While Cleaver Greene is a brilliant and driven...           Netflix   \n",
       "9  In Colombia, the DEA's new director targets a ...           Netflix   \n",
       "\n",
       "   Similarity Score  \n",
       "0          0.635364  \n",
       "1          0.563305  \n",
       "2          0.555709  \n",
       "3          0.554274  \n",
       "4          0.548441  \n",
       "5          0.541296  \n",
       "6          0.540868  \n",
       "7          0.531299  \n",
       "8          0.526270  \n",
       "9          0.523722  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"Ganglands\", cosine_simTFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N Grams\n",
    "This did not actually run but due to filtering of the data via the Dash app components, we were able to implement NGrams text mining method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', token_pattern=r'\\b[a-zA-Z]{3,}\\b', ngram_range=(1, 1));\n",
    "matrix = vectorizer.fit_transform(df_prep[\"Textual Info\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.85 GiB for an array with shape (22741, 22741) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9960/1831964600.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcosine_simNGram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\kunal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1357\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m     \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_normalized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kunal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"toarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     ):\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kunal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kunal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.85 GiB for an array with shape (22741, 22741) and data type float64"
     ]
    }
   ],
   "source": [
    "cosine_simNGram = cosine_similarity(matrix, matrix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_simNGram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9960/1704077376.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ganglands\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine_simNGram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_simNGram' is not defined"
     ]
    }
   ],
   "source": [
    "get_recommendations(\"Ganglands\", cosine_simNGram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07fcc30a38d1ecd00416a20ffc3bb9ba1ff350e42774c526eac392e139b99617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
